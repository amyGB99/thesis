\begin{conclusions}
Se propuso \textit{HAutoML-Bench} un software encaminado a la evaluación de herramientas de aprendizaje automático en escenarios heterogéneos.
Este benchmark permite la descarga de conjuntos de datos en un formato común que somenten a pruebas complejas a los sistemas AutoML. 
Se apoya en las experiencias y trata de no cometer los errores de las metodologías del diseño de los benchmark antecesores. Los conjuntos de datos que agrupa 
poseen variedad en su forma de modelado, en sus tipos de datos y pertenecen a variados dominios de aplicación. Cada uno fue seleccionado llevando a cabo una estrategia 
que disminuye los sesgos de selección y que pone como prioridad respetar la estructura e interpretación de cada uno de su tipos de datos.

\textit{HAutoML-Bench} es fácil de usar, se instala y se inicializa de una manera sencilla. Además, brinda para cada prueba un entorno de evaluación para cuantificar 
el rendimiento de los sistemas AutoML. También, cada una de las funcionalidades que implementa se pueden emplear sin muchas complicaciones consultando su documetación 
oficial.

Las evaluaciones cualitativas realizadas sobre los sistemas AutoML permitieron afirmar que si existen sistemas que puede ser evaluados utilizando \textit{HAutoML-Bench}.
Las evaluaciones cuantitativas sobre el sistema AutoGluon confirmaron que sí es posible cuantificar la flexibildad de una herramienta de aprendizaje automático para 
enfrentarse a problemas de la vida real en donde la información se encuentra muy poco procesada y que necesita técnicas del dominio para su solución.

\end{conclusions}
